# LÆ°u Káº¿t Quáº£ PhÃ¢n Loáº¡i KhÃ¡ch HÃ ng vÃ o AWS S3

## Tá»•ng Quan

Trong bÆ°á»›c cuá»‘i cÃ¹ng, chÃºng ta sáº½:
1. âœ… **LÆ°u file CSV** chá»©a dá»¯ liá»‡u phÃ¢n loáº¡i khÃ¡ch hÃ ng
2. âœ… **Upload lÃªn AWS S3** Ä‘á»ƒ lÆ°u trá»¯ vÃ  sá»­ dá»¥ng sau
3. âœ… **Chuáº©n bá»‹ dá»¯ liá»‡u** cho cÃ¡c bÆ°á»›c tiáº¿p theo (Bedrock, BI tools)
---
```python 
def save_dataframe_to_s3(df, bucket, folder, file_name):
    """
    Ghi DataFrame vÃ o S3 folder cá»¥ thá»ƒ
    
    Parameters:
    df (pd.DataFrame): DataFrame cáº§n lÆ°u
    bucket (str): S3 bucket name
    folder (str): Folder path (vd: 'output_data/')
    file_name (str): TÃªn file (vd: 'rfm_scores.csv')
    """
    try:
        key = f"{folder}{file_name}"
        
        # convert DataFrame to CSV string
        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False)
        
        # wirte to S3
        s3_client.put_object(
            Bucket=bucket,
            Key=key,
            Body=csv_buffer.getvalue()
        )
        
        print(f"âœ… Successfully saved to s3://{bucket}/{key}")
        print(f"   Rows: {len(df)}, Columns: {len(df.columns)}")
        return True
        
    except Exception as e:
        print(f"âŒ Error saving to S3: {e}")
        return False

save_dataframe_to_s3(df_RFM3, 'lab-aws-workshop', 'output_data/','customer_segmentation.csv')
```
---
## Nhá»¯ng File ÄÆ°á»£c LÆ°u

### **File CSV ChÃ­nh:**

```
ğŸ“ s3://lab-aws-workshop/output_data/
â”œâ”€â”€ customer_segmentation.csv  â† File chá»©a thá»‘ng kÃª 4 segment
```

---

**ğŸ‰ Xin chÃºc má»«ng!**

Báº¡n Ä‘Ã£ hoÃ n táº¥t phÃ¢n tÃ­ch RFM vÃ  K-Means Clustering trong AWS SageMaker!

**Tiáº¿p theo:** Sá»­ dá»¥ng dá»¯ liá»‡u nÃ y vá»›i AWS Bedrock Ä‘á»ƒ táº¡o AI-powered marketing strategies [pháº§n tiáº¿p theo](3.0.Bedrock.md)! ğŸš€